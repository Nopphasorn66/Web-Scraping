# # app.py
# # -*- coding: utf-8 -*-
# import ast, re, warnings, numpy as np, pandas as pd
# import streamlit as st
# import altair as alt

# from functools import partial
# from sklearn.model_selection import train_test_split
# from sklearn.pipeline import Pipeline, FeatureUnion
# from sklearn.preprocessing import FunctionTransformer
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.linear_model import Ridge
# from sklearn.metrics import mean_absolute_error, mean_squared_error

# warnings.filterwarnings("ignore", category=UserWarning)

# # =========================
# # Streamlit UI
# # =========================
# st.set_page_config(page_title="‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥", page_icon="üé¨", layout="wide")
# st.title("üé¨ ‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥")
# st.caption("‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Rotten Tomatoes + ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ ML (Ridge + TF-IDF) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡πà‡∏≤‡πÉ‡∏Ñ‡∏£ ‚Äò‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‚Äô ‡∏ó‡∏±‡πâ‡∏á‡∏ú‡∏π‡πâ‡∏ä‡∏° (Audience) ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå (Tomatometer)")

# ALL_GENRES = ['action','adventure','comedy','crime',
#               'documentary','history','horror','music',
#               'romance','sports','war']

# # =========================
# # Utilities
# # =========================
# def safe_rmse(y_true, y_pred):
#     try:
#         return mean_squared_error(y_true, y_pred, squared=False)
#     except TypeError:
#         return np.sqrt(mean_squared_error(y_true, y_pred))

# def pct_to_float(x):
#     if pd.isna(x): return np.nan
#     m = re.search(r"(\d+(\.\d+)?)", str(x))
#     return float(m.group(1)) if m else np.nan

# def to_list(x):
#     if isinstance(x, list): return x
#     if pd.isna(x): return []
#     s = str(x).strip()
#     try:
#         v = ast.literal_eval(s)
#         if isinstance(v, list): return [str(t).strip() for t in v]
#         if isinstance(v, str): return [v.strip()] if v.strip() else []
#     except Exception:
#         pass
#     if "," in s: return [t.strip() for t in s.split(",") if t.strip()]
#     return [s] if s else []

# def normalize_tokens(L):
#     out=[]
#     for w in L:
#         w = re.sub(r"\s+", "_", str(w).strip().lower())
#         w = re.sub(r"[^a-z0-9_+\'\-]", "", w)
#         if w: out.append(w)
#     return out

# def list_to_token_str(L):  # actors/directors
#     return " ".join(normalize_tokens(L))

# def genre_to_token_str(L):
#     return " ".join([re.sub(r"\s+","_",str(g).strip().lower()) for g in L if str(g).strip()])

# def _get_vocab(vec):
#     try: return vec.get_feature_names_out()
#     except AttributeError: return vec.get_feature_names()

# def tok2name(tok):
#     return tok.replace("_"," ").title()

# # ---------- FunctionTransformer helpers (no lambda) ----------
# def select_field(X, field):
#     # X ‡πÄ‡∏õ‡πá‡∏ô DataFrame; ‡∏Ñ‡∏∑‡∏ô Series/array ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
#     return X[field]

# def make_field_selector(field):
#     # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô top-level + kw_args ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ picklable
#     return FunctionTransformer(select_field, validate=False, kw_args={"field": field})

# # =========================
# # Load data
# # =========================
# @st.cache_data(show_spinner=True)
# def load_movies(csv_path="movies.csv"):
#     df = pd.read_csv(csv_path)

#     # scores
#     df["tom_score_num"] = df.get("tom_score", np.nan).apply(pct_to_float)
#     df["pop_score_num"] = df.get("pop_score", np.nan).apply(pct_to_float)

#     # drop ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ "‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà" ‡πÄ‡∏õ‡πá‡∏ô 0%
#     both_zero = (df.get("tom_score","").astype(str).str.strip()=="0%") & \
#                 (df.get("pop_score","").astype(str).str.strip()=="0%")
#     df = df[~both_zero].copy()

#     # lists
#     for col in ["ld_actors","ld_directors","genres"]:
#         if col in df.columns:
#             df[col] = df[col].apply(to_list)
#         else:
#             df[col] = [[] for _ in range(len(df))]

#     # strings for vectorizers
#     df["actors_str"]    = df["ld_actors"].apply(list_to_token_str)
#     df["directors_str"] = df["ld_directors"].apply(list_to_token_str)
#     df["genres_str"]    = df["genres"].apply(genre_to_token_str)

#     # display fields
#     df["release_date_disp"] = df.get("release_date","").astype(str)
#     df["score_mean"] = df[["tom_score_num","pop_score_num"]].mean(axis=1)

#     return df

# df = load_movies("movies.csv")
# if df.empty:
#     st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô movies.csv ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á")
#     st.stop()

# # =========================
# # Build features / Train
# # =========================
# def build_features(max_actors=2000, max_directors=800, max_genres=120):
#     actors_pipe = Pipeline([
#         ("sel", make_field_selector("actors_str")),
#         ("tfidf", TfidfVectorizer(max_features=max_actors,
#                                   token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
#     ])
#     directors_pipe = Pipeline([
#         ("sel", make_field_selector("directors_str")),
#         ("tfidf", TfidfVectorizer(max_features=max_directors,
#                                   token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
#     ])
#     genres_pipe = Pipeline([
#         ("sel", make_field_selector("genres_str")),
#         ("tfidf", TfidfVectorizer(max_features=max_genres,
#                                   token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
#     ])
#     return FeatureUnion([("actors", actors_pipe),
#                          ("directors", directors_pipe),
#                          ("genres", genres_pipe)])

# @st.cache_resource(show_spinner=True)
# def train_and_eval(df, target_col="pop_score_num", test_size=0.2, alpha=5.0):
#     df_ = df.dropna(subset=[target_col]).copy()
#     if df_.empty:
#         return None, None, {"target": target_col, "error": "no rows"}

#     X = df_[["actors_str","directors_str","genres_str"]]
#     y = df_[target_col].values

#     Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)

#     feats = build_features()
#     XtrF = feats.fit_transform(Xtr)
#     XteF = feats.transform(Xte)

#     model = Ridge(alpha=alpha)
#     model.fit(XtrF, ytr)
#     pred = model.predict(XteF)

#     mae, rmse = mean_absolute_error(yte, pred), safe_rmse(yte, pred)
#     baseline = float(np.mean(ytr))
#     mae_bl = mean_absolute_error(yte, np.full_like(yte, baseline))
#     rmse_bl = safe_rmse(yte, np.full_like(yte, baseline))

#     try:
#         from sklearn.metrics import r2_score
#         r2 = r2_score(yte, pred)
#     except Exception:
#         r2 = np.nan

#     report = dict(target=target_col, n_train=len(ytr), n_test=len(yte),
#                   MAE=float(mae), RMSE=float(rmse), R2=float(r2),
#                   baseline_mean=baseline, MAE_baseline=float(mae_bl), RMSE_baseline=float(rmse_bl))
#     return feats, model, report

# def get_token_weights(features_union, model):
#     if features_union is None or model is None:
#         return pd.DataFrame(columns=["block","token","weight"])
#     names=[]; weights=[]; start=0
#     for name, pipe in features_union.transformer_list:
#         vec = pipe.named_steps["tfidf"]
#         vocab = _get_vocab(vec)
#         coef_slice = model.coef_[start:start+len(vocab)]
#         start += len(vocab)
#         for tok, w in zip(vocab, coef_slice):
#             names.append((name, tok)); weights.append(w)
#     fw = pd.DataFrame({"block":[b for b,_ in names],
#                        "token":[t for _,t in names],
#                        "weight":weights}).sort_values("weight", ascending=False)
#     return fw

# # =========================
# # Controls
# # =========================
# colA, colB, colC, colD = st.columns([1.8,1.2,1,1])
# with colA:
#     sel_genres = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏ô‡∏±‡∏á (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó)", ALL_GENRES, default=["comedy"])
# with colB:
#     top_n = st.number_input("Top N ‡∏´‡∏ô‡∏±‡∏á (‡πÇ‡∏ä‡∏ß‡πå/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)", 5, 100, 20, step=5)
# with colC:
#     min_app = st.number_input("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡∏ä‡∏∑‡πà‡∏≠ (appearances)", 1, 10, 2, step=1)
# with colD:
#     focus = st.selectbox("‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", ["balanced","audience","critics"])

# if not sel_genres:
#     st.info("‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
#     st.stop()

# # =========================
# # Train models + metrics
# # =========================
# with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•..."):
#     feats_pop, model_pop, rep_pop = train_and_eval(df, target_col="pop_score_num")
#     feats_tom, model_tom, rep_tom = train_and_eval(df, target_col="tom_score_num")
#     fw_pop = get_token_weights(feats_pop, model_pop)
#     fw_tom = get_token_weights(feats_tom, model_tom)

# st.subheader("üìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
# met_col1, met_col2 = st.columns(2)
# with met_col1:
#     st.markdown("**Audience model (pop_score_num)**")
#     st.write(rep_pop)
# with met_col2:
#     st.markdown("**Critics model (tom_score_num)**")
#     st.write(rep_tom)
# st.caption("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Ridge + TF-IDF ‡πÉ‡∏´‡πâ ‚Äò‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‚Äô ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‚Äî ‡∏î‡∏π‡∏Ñ‡πà‡∏≤ appearances ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏™‡∏°‡∏≠")

# # =========================
# # Slide show (‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)
# # =========================
# mask_sel = df["genres"].apply(lambda L: any(g.lower() in [str(x).lower() for x in L] for g in sel_genres))
# df_sel = df.loc[mask_sel].copy().sort_values("score_mean", ascending=False).head(int(top_n))

# st.markdown("---")
# st.subheader("üñºÔ∏è ‡∏™‡πÑ‡∏•‡∏î‡πå‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏´‡∏ô‡∏±‡∏á (Tom vs Audience) ‚Äî ‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
# if df_sel.empty:
#     st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡∏±‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
# else:
#     cols = st.columns([1,1,6])
#     if "slide_idx" not in st.session_state:
#         st.session_state.slide_idx = 0
#     with cols[0]:
#         if st.button("‚èÆÔ∏è Prev"):
#             st.session_state.slide_idx = (st.session_state.slide_idx - 1) % len(df_sel)
#     with cols[1]:
#         if st.button("Next ‚è≠Ô∏è"):
#             st.session_state.slide_idx = (st.session_state.slide_idx + 1) % len(df_sel)

#     cur = df_sel.iloc[st.session_state.slide_idx]
#     st.subheader(f"{st.session_state.slide_idx+1}/{len(df_sel)} ‚Äî {cur['title']}")
#     st.caption(f"Release: {cur['release_date_disp']}  |  Link: {cur.get('url','-')}")
#     slide_scores = pd.DataFrame({
#         "Metric": ["Tomatometer", "Audience"],
#         "Score": [cur.get("tom_score_num", np.nan), cur.get("pop_score_num", np.nan)]
#     })
#     chart = alt.Chart(slide_scores).mark_bar().encode(
#         x=alt.X("Metric:N", title=None),
#         y=alt.Y("Score:Q", scale=alt.Scale(domain=[0, 100])),
#         tooltip=["Metric","Score"]
#     ).properties(height=220)
#     st.altair_chart(chart, use_container_width=True)

# # =========================
# # Recommendations
# # =========================
# def appearances_in_genre_combo(df, genres_selected):
#     m = df["genres"].apply(lambda L: any(g.lower() in [str(x).lower() for x in L] for g in genres_selected))
#     dfg = df.loc[m]
#     if dfg.empty:
#         return pd.Series(dtype=int), pd.Series(dtype=int), dfg
#     act_counts = pd.Series([a for L in dfg["ld_actors"] for a in L]).value_counts()
#     dir_counts = pd.Series([d for L in dfg["ld_directors"] for d in L]).value_counts()
#     return act_counts, dir_counts, dfg

# def combine_fw(fw_aud, fw_crit, block, mode="balanced"):
#     A = fw_aud[fw_aud["block"]==block][["token","weight"]].rename(columns={"weight":"w_aud"})
#     C = fw_crit[fw_crit["block"]==block][["token","weight"]].rename(columns={"weight":"w_crit"})
#     M = pd.merge(A, C, on="token", how="outer").fillna(0.0)
#     if mode=="audience":
#         M["w"] = M["w_aud"]
#     elif mode=="critics":
#         M["w"] = M["w_crit"]
#     else:
#         # balanced: standardize ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
#         if len(M)>0:
#             for c in ["w_aud","w_crit"]:
#                 std = M[c].std(ddof=0)
#                 if std > 1e-9:
#                     M[c] = (M[c]-M[c].mean())/std
#         M["w"] = 0.5*M["w_aud"] + 0.5*M["w_crit"]
#     return M[["token","w"]].sort_values("w", ascending=False)

# def recommend_people(df, fw_pop, fw_tom, genres_selected, focus="balanced", top_k=20, min_appearances=2):
#     acts_combo = combine_fw(fw_pop, fw_tom, "actors", mode=focus)
#     dirs_combo = combine_fw(fw_pop, fw_tom, "directors", mode=focus)

#     act_counts, dir_counts, dfg = appearances_in_genre_combo(df, genres_selected)

#     def top_block(combo_df, counts, top_k):
#         out = combo_df.copy()
#         out["name"] = out["token"].apply(tok2name)
#         if not counts.empty:
#             out["appearances"] = out["name"].map(counts).fillna(0).astype(int)
#             out = out[out["appearances"] >= int(min_appearances)]
#         else:
#             out["appearances"] = 0
#         return out.nlargest(top_k, "w")[["name","w","appearances"]]

#     return {
#         "actors": top_block(acts_combo, act_counts, top_k),
#         "directors": top_block(dirs_combo, dir_counts, top_k),
#         "df_subset": dfg
#     }

# st.markdown("---")
# st.subheader("üèÜ ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)")

# recs = recommend_people(df, fw_pop, fw_tom, sel_genres,
#                         focus=focus, top_k=30, min_appearances=int(min_app))

# colR1, colR2 = st.columns(2)
# with colR1:
#     st.markdown("**Actors (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)**")
#     st.dataframe(recs["actors"].rename(columns={"w":"weight"}), use_container_width=True)
# with colR2:
#     st.markdown("**Directors (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)**")
#     st.dataframe(recs["directors"].rename(columns={"w":"weight"}), use_container_width=True)

# # =========================
# # Reference titles
# # =========================
# st.markdown("---")
# st.subheader("üéûÔ∏è ‡∏´‡∏ô‡∏±‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡∏Ñ‡∏±‡∏î‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô)")
# st.dataframe(
#     df_sel[["title","release_date_disp","tom_score","pop_score","url"]]
#       .rename(columns={"release_date_disp":"release_date"}),
#     use_container_width=True
# )

# # =========================
# # Practical summary
# # =========================
# st.markdown("---")
# st.header("üßæ ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥")
# actors_short = ", ".join(recs["actors"]["name"].head(5).tolist()) if not recs["actors"].empty else "-"
# dirs_short   = ", ".join(recs["directors"]["name"].head(3).tolist()) if not recs["directors"].empty else "-"
# st.success(
#     f"‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡∏±‡∏á‡πÅ‡∏ô‡∏ß **{', '.join([g.capitalize() for g in sel_genres])}**\n"
#     f"- **‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å):** {actors_short}\n"
#     f"- **‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å):** {dirs_short}\n"
#     f"- ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡∏ì‡∏ë‡πå `appearances ‚â• {int(min_app)}` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏≠‡∏Ñ‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å Top N = {int(top_n)} ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å\n"
#     f"- ‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö: **{focus}** (audience/critics/balanced)"
# )


# app.py
# -*- coding: utf-8 -*-
import ast, re, warnings, numpy as np, pandas as pd
import streamlit as st
import altair as alt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.preprocessing import FunctionTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error

warnings.filterwarnings("ignore", category=UserWarning)

# =========================
# Page config & Router
# =========================
st.set_page_config(page_title="‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥", page_icon="üé¨", layout="wide")
page = st.sidebar.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡πâ‡∏≤", ["‡∏´‡∏ô‡πâ‡∏≤ 1: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡∏´‡∏ô‡πâ‡∏≤ 2: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• (ML)"])

ALL_GENRES = ['action','adventure','comedy','crime',
              'documentary','history','horror','music',
              'romance','sports','war']

# =========================
# Utilities (no lambda for pickling safety)
# =========================
def safe_rmse(y_true, y_pred):
    try:
        return mean_squared_error(y_true, y_pred, squared=False)
    except TypeError:
        return np.sqrt(mean_squared_error(y_true, y_pred))

def pct_to_float(x):
    if pd.isna(x): return np.nan
    m = re.search(r"(\d+(\.\d+)?)", str(x))
    return float(m.group(1)) if m else np.nan

def to_list(x):
    if isinstance(x, list): return x
    if pd.isna(x): return []
    s = str(x).strip()
    try:
        v = ast.literal_eval(s)
        if isinstance(v, list): return [str(t).strip() for t in v]
        if isinstance(v, str): return [v.strip()] if v.strip() else []
    except Exception:
        pass
    if "," in s: return [t.strip() for t in s.split(",") if t.strip()]
    return [s] if s else []

def normalize_tokens(L):
    out=[]
    for w in L:
        w = re.sub(r"\s+", "_", str(w).strip().lower())
        w = re.sub(r"[^a-z0-9_+\'\-]", "", w)
        if w: out.append(w)
    return out

def list_to_token_str(L):  # for actors/directors
    return " ".join(normalize_tokens(L))

def genre_to_token_str(L):
    return " ".join([re.sub(r"\s+","_",str(g).strip().lower()) for g in L if str(g).strip()])

def _get_vocab(vec):
    try: return vec.get_feature_names_out()
    except AttributeError: return vec.get_feature_names()

def tok2name(tok):
    return tok.replace("_"," ").title()

def select_field(X, field):
    return X[field]

def make_field_selector(field):
    return FunctionTransformer(select_field, validate=False, kw_args={"field": field})

# =========================
# Load data
# =========================
@st.cache_data(show_spinner=True)
def load_movies(csv_path="movies.csv"):
    df = pd.read_csv(csv_path)

    # scores
    df["tom_score_num"] = df.get("tom_score", np.nan).apply(pct_to_float)
    df["pop_score_num"] = df.get("pop_score", np.nan).apply(pct_to_float)

    # drop ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ "‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà" ‡πÄ‡∏õ‡πá‡∏ô 0%
    both_zero = (df.get("tom_score","").astype(str).str.strip()=="0%") & \
                (df.get("pop_score","").astype(str).str.strip()=="0%")
    df = df[~both_zero].copy()

    # lists
    for col in ["ld_actors","ld_directors","genres"]:
        if col in df.columns:
            df[col] = df[col].apply(to_list)
        else:
            df[col] = [[] for _ in range(len(df))]

    # strings for vectorizers
    df["actors_str"]    = df["ld_actors"].apply(list_to_token_str)
    df["directors_str"] = df["ld_directors"].apply(list_to_token_str)
    df["genres_str"]    = df["genres"].apply(genre_to_token_str)

    # display fields
    df["release_date_disp"] = df.get("release_date","").astype(str)
    df["score_mean"] = df[["tom_score_num","pop_score_num"]].mean(axis=1)

    return df

df = load_movies("movies.csv")
if df.empty:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô movies.csv ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á")
    st.stop()

# =========================
# Build features / Train
# =========================
def build_features(max_actors=2000, max_directors=800, max_genres=120):
    actors_pipe = Pipeline([
        ("sel", make_field_selector("actors_str")),
        ("tfidf", TfidfVectorizer(max_features=max_actors,
                                  token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
    ])
    directors_pipe = Pipeline([
        ("sel", make_field_selector("directors_str")),
        ("tfidf", TfidfVectorizer(max_features=max_directors,
                                  token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
    ])
    genres_pipe = Pipeline([
        ("sel", make_field_selector("genres_str")),
        ("tfidf", TfidfVectorizer(max_features=max_genres,
                                  token_pattern=r"(?u)\b\w[\w_\-\+']+\b"))
    ])
    return FeatureUnion([("actors", actors_pipe),
                         ("directors", directors_pipe),
                         ("genres", genres_pipe)])

@st.cache_resource(show_spinner=True)
def train_and_eval(df, target_col="pop_score_num", test_size=0.2, alpha=5.0):
    df_ = df.dropna(subset=[target_col]).copy()
    if df_.empty:
        return None, None, {"target": target_col, "error": "no rows"}

    X = df_[["actors_str","directors_str","genres_str"]]
    y = df_[target_col].values

    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)

    feats = build_features()
    XtrF = feats.fit_transform(Xtr)
    XteF = feats.transform(Xte)

    model = Ridge(alpha=alpha)
    model.fit(XtrF, ytr)
    pred = model.predict(XteF)

    mae, rmse = mean_absolute_error(yte, pred), safe_rmse(yte, pred)
    baseline = float(np.mean(ytr))
    mae_bl = mean_absolute_error(yte, np.full_like(yte, baseline))
    rmse_bl = safe_rmse(yte, np.full_like(yte, baseline))

    try:
        from sklearn.metrics import r2_score
        r2 = r2_score(yte, pred)
    except Exception:
        r2 = np.nan

    report = dict(target=target_col, n_train=len(ytr), n_test=len(yte),
                  MAE=float(mae), RMSE=float(rmse), R2=float(r2),
                  baseline_mean=baseline, MAE_baseline=float(mae_bl), RMSE_baseline=float(rmse_bl))
    return feats, model, report

def get_token_weights(features_union, model):
    if features_union is None or model is None:
        return pd.DataFrame(columns=["block","token","weight"])
    names=[]; weights=[]; start=0
    for name, pipe in features_union.transformer_list:
        vec = pipe.named_steps["tfidf"]
        vocab = _get_vocab(vec)
        coef_slice = model.coef_[start:start+len(vocab)]
        start += len(vocab)
        for tok, w in zip(vocab, coef_slice):
            names.append((name, tok)); weights.append(w)
    fw = pd.DataFrame({"block":[b for b,_ in names],
                       "token":[t for _,t in names],
                       "weight":weights}).sort_values("weight", ascending=False)
    return fw

# =========================
# Common helpers
# =========================
def appearances_in_genre_combo(df, genres_selected):
    m = df["genres"].apply(lambda L: any(g.lower() in [str(x).lower() for x in L] for g in genres_selected))
    dfg = df.loc[m]
    if dfg.empty:
        return pd.Series(dtype=int), pd.Series(dtype=int), dfg
    act_counts = pd.Series([a for L in dfg["ld_actors"] for a in L]).value_counts()
    dir_counts = pd.Series([d for L in dfg["ld_directors"] for d in L]).value_counts()
    return act_counts, dir_counts, dfg

def combine_fw(fw_aud, fw_crit, block, mode="balanced"):
    A = fw_aud[fw_aud["block"]==block][["token","weight"]].rename(columns={"weight":"w_aud"})
    C = fw_crit[fw_crit["block"]==block][["token","weight"]].rename(columns={"weight":"w_crit"})
    M = pd.merge(A, C, on="token", how="outer").fillna(0.0)
    if mode=="audience":
        M["w"] = M["w_aud"]
    elif mode=="critics":
        M["w"] = M["w_crit"]
    else:
        # balanced: z-score ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
        if len(M)>0:
            for c in ["w_aud","w_crit"]:
                std = M[c].std(ddof=0)
                if std > 1e-9:
                    M[c] = (M[c]-M[c].mean())/std
        M["w"] = 0.5*M["w_aud"] + 0.5*M["w_crit"]
    return M[["token","w"]].sort_values("w", ascending=False)

def recommend_people(df, fw_pop, fw_tom, genres_selected, focus="balanced", top_k=20, min_appearances=2):
    acts_combo = combine_fw(fw_pop, fw_tom, "actors", mode=focus)
    dirs_combo = combine_fw(fw_pop, fw_tom, "directors", mode=focus)
    act_counts, dir_counts, dfg = appearances_in_genre_combo(df, genres_selected)

    def top_block(combo_df, counts, top_k):
        out = combo_df.copy()
        out["name"] = out["token"].apply(tok2name)
        if not counts.empty:
            out["appearances"] = out["name"].map(counts).fillna(0).astype(int)
            out = out[out["appearances"] >= int(min_appearances)]
        else:
            out["appearances"] = 0
        return out.nlargest(top_k, "w")[["name","w","appearances"]]

    return {
        "actors": top_block(acts_combo, act_counts, top_k),
        "directors": top_block(dirs_combo, dir_counts, top_k),
        "df_subset": dfg
    }

def best_title_for_person(df_subset, person_name, role="actor"):
    """‡∏´‡∏≤ 1 ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
    if df_subset.empty: return None
    col = "ld_actors" if role=="actor" else "ld_directors"
    m = df_subset[col].apply(lambda L: person_name in L)
    dfx = df_subset.loc[m].copy()
    if dfx.empty: return None
    dfx = dfx.sort_values("score_mean", ascending=False)
    row = dfx.iloc[0]
    return {
        "title": row.get("title","-"),
        "audience_score": row.get("pop_score","-"),
        "critics_score": row.get("tom_score","-"),
        "url": row.get("url","-")
    }

# =========================
# Train models once per session
# =========================
@st.cache_resource(show_spinner=True)
def train_models_once(df):
    feats_pop, model_pop, rep_pop = train_and_eval(df, target_col="pop_score_num")
    feats_tom, model_tom, rep_tom = train_and_eval(df, target_col="tom_score_num")
    fw_pop = get_token_weights(feats_pop, model_pop)
    fw_tom = get_token_weights(feats_tom, model_tom)
    return (feats_pop, model_pop, rep_pop,
            feats_tom, model_tom, rep_tom,
            fw_pop, fw_tom)

(feats_pop, model_pop, rep_pop,
 feats_tom, model_tom, rep_tom,
 fw_pop, fw_tom) = train_models_once(df)

# =========================
# PAGE 1: ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
# =========================
if page.startswith("‡∏´‡∏ô‡πâ‡∏≤ 1"):
    st.title("üé¨ ‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥ ‚Äî ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    st.caption("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ô‡∏ß/‡πÄ‡∏Å‡∏ì‡∏ë‡πå ‚Üí ‡∏î‡∏π‡∏™‡πÑ‡∏•‡∏î‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ‚Üí ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ‚Üí ‡∏´‡∏ô‡∏±‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á ‚Üí ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥")

    # ----- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á + ‡∏™‡πÑ‡∏•‡∏î‡πå‡πÇ‡∏ä‡∏ß‡πå -----
    st.subheader("‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ & ‡∏™‡πÑ‡∏•‡∏î‡πå‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô")
    colA, colB, colC, colD = st.columns([1.8,1.2,1,1])
    with colA:
        sel_genres = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏ô‡∏±‡∏á (‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏î‡πâ)", ALL_GENRES, default=["comedy"])
    with colB:
        top_n = st.number_input("Top N ‡∏´‡∏ô‡∏±‡∏á (‡πÇ‡∏ä‡∏ß‡πå/‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)", 5, 100, 20, step=5)
    with colC:
        min_app = st.number_input("‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏á‡∏≤‡∏ô/‡∏ä‡∏∑‡πà‡∏≠ (appearances)", 1, 10, 2, step=1)
    with colD:
        focus = st.selectbox("‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", ["balanced","audience","critics"])

    if not sel_genres:
        st.info("‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó")
        st.stop()

    # ‡∏™‡πÑ‡∏•‡∏î‡πå‡πÇ‡∏ä‡∏ß‡πå
    mask_sel = df["genres"].apply(lambda L: any(g.lower() in [str(x).lower() for x in L] for g in sel_genres))
    df_sel = df.loc[mask_sel].copy().sort_values("score_mean", ascending=False).head(int(top_n))

    if df_sel.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡∏±‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    else:
        cols = st.columns([1,1,6])
        if "slide_idx" not in st.session_state:
            st.session_state.slide_idx = 0
        with cols[0]:
            if st.button("‚èÆÔ∏è Prev"):
                st.session_state.slide_idx = (st.session_state.slide_idx - 1) % len(df_sel)
        with cols[1]:
            if st.button("Next ‚è≠Ô∏è"):
                st.session_state.slide_idx = (st.session_state.slide_idx + 1) % len(df_sel)

        cur = df_sel.iloc[st.session_state.slide_idx]
        st.subheader(f"{st.session_state.slide_idx+1}/{len(df_sel)} ‚Äî {cur['title']}")
        st.caption(f"Release: {cur['release_date_disp']}  |  Link: {cur.get('url','-')}")
        slide_scores = pd.DataFrame({
            "Metric": ["Tomatometer", "Audience"],
            "Score": [cur.get("tom_score_num", np.nan), cur.get("pop_score_num", np.nan)]
        })
        chart = alt.Chart(slide_scores).mark_bar().encode(
            x=alt.X("Metric:N", title=None),
            y=alt.Y("Score:Q", scale=alt.Scale(domain=[0, 100])),
            tooltip=["Metric","Score"]
        ).properties(height=220)
        st.altair_chart(chart, use_container_width=True)

    # ----- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ -----
    st.markdown("---")
    st.subheader("‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
    recs = recommend_people(df, fw_pop, fw_tom, sel_genres,
                            focus=focus, top_k=30, min_appearances=int(min_app))
    colR1, colR2 = st.columns(2)
    with colR1:
        st.markdown("**Actors (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)**")
        st.dataframe(recs["actors"].rename(columns={"w":"weight"}),
                     use_container_width=True)
    with colR2:
        st.markdown("**Directors (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)**")
        st.dataframe(recs["directors"].rename(columns={"w":"weight"}),
                     use_container_width=True)

        # ----- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏´‡∏ô‡∏±‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á -----
    st.markdown("---")
    st.subheader("‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏´‡∏ô‡∏±‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡∏Ñ‡∏±‡∏î‡∏ó‡∏µ‡∏°‡∏á‡∏≤‡∏ô)")

    if not df_sel.empty:
        ref_tbl = df_sel.copy()

        # ‡∏•‡∏ö release_date ‡πÄ‡∏î‡∏¥‡∏°‡∏≠‡∏≠‡∏Å‡∏Å‡∏±‡∏ô‡∏ä‡∏ô‡∏Å‡∏±‡∏ô
        if "release_date" in ref_tbl.columns and "release_date_disp" in ref_tbl.columns:
            ref_tbl = ref_tbl.drop(columns=["release_date"])

        ref_tbl = ref_tbl.rename(columns={
            "title": "name",
            "release_date_disp": "release_date_show",
            "pop_score": "audience_score",
            "tom_score": "critics_score"
        })

        st.dataframe(ref_tbl[["name","release_date_show","audience_score","critics_score","url"]],
                    use_container_width=True)
    else:
        st.info("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")


    # ----- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ -----
    st.markdown("---")
    st.subheader("‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥")

    actors_short = ", ".join(recs["actors"]["name"].head(5).tolist()) if not recs["actors"].empty else "-"
    dirs_short   = ", ".join(recs["directors"]["name"].head(3).tolist()) if not recs["directors"].empty else "-"

    # ‡∏´‡∏≤‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡πÄ‡∏î‡πà‡∏ô‡∏Ñ‡∏ô‡∏•‡∏∞ 1 ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
    best_cast_work = "-"
    best_dir_work  = "-"
    if not recs["df_subset"].empty:
        if not recs["actors"].empty:
            top_actor = recs["actors"]["name"].iloc[0]
            ba = best_title_for_person(recs["df_subset"], top_actor, role="actor")
            if ba:
                best_cast_work = f"{top_actor} ‚Üí {ba['title']} (Aud: {ba['audience_score']}, Crit: {ba['critics_score']})"
        if not recs["directors"].empty:
            top_dir = recs["directors"]["name"].iloc[0]
            bd = best_title_for_person(recs["df_subset"], top_dir, role="director")
            if bd:
                best_dir_work = f"{top_dir} ‚Üí {bd['title']} (Aud: {bd['audience_score']}, Crit: {bd['critics_score']})"

    st.success(
        f"‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å): {actors_short}\n\n"
        f"‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 3 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å): {dirs_short}\n\n"
        f"‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö (‡∏Ñ‡∏ô‡∏•‡∏∞ 1 ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á):\n"
        f"- {best_cast_work}\n"
        f"- {best_dir_work}\n\n"
        f"‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡∏ì‡∏ë‡πå appearances ‚â• {int(min_app)} ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏≠‡∏Ñ‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å Top N = {int(top_n)} ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å\n"
        f"‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö: {focus} (audience/critics/balanced)"
    )

# =========================
# PAGE 2: ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•
# =========================
else:
    st.title("üß† ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•: ‡∏ó‡∏≥‡πÑ‡∏° TF-IDF + Ridge?")
    st.markdown("""
**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢**: ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡∏° (Audience) ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡πå (Tomatometer) ‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á/‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö/‡πÅ‡∏ô‡∏ß‡∏´‡∏ô‡∏±‡∏á  
**‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å**: ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢ **TF-IDF** ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ **Ridge Regression** ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏° L2 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfit

### ‡∏ó‡∏≥‡πÑ‡∏° TF-IDF?
- ‡∏•‡∏î‡∏≠‡∏¥‡∏ó‡∏ò‡∏¥‡∏û‡∏•‡∏Ñ‡∏≥/‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡πÇ‡∏ú‡∏•‡πà‡∏ö‡πà‡∏≠‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô super-star) ‡πÉ‡∏´‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏õ‡∏≤‡∏£‡πå‡∏™ (‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢) ‡πÅ‡∏•‡∏∞ **‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢**

### ‡∏ó‡∏≥‡πÑ‡∏° Ridge?
- ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å TF-IDF ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡∏õ‡∏≤‡∏£‡πå‡∏™ ‚Üí L2 ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ **‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô**
- ‡πÑ‡∏î‡πâ **‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å** ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ó‡πÄ‡∏Ñ‡πá‡∏ô‡∏ï‡∏£‡∏á ‡πÜ ‚Üí ‡∏ô‡∏≥‡πÑ‡∏õ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà ‚Äú‡∏´‡∏ô‡∏∏‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‚Äù ‡πÑ‡∏î‡πâ

### ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏≠‡∏∑‡πà‡∏ô
- **RandomForest/XGBoost**: ‡∏≠‡∏≤‡∏à‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà ‡πÅ‡∏ï‡πà‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° ‚Äú‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏Ñ‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‚Äù ‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
- **ElasticNet**: ‡∏Ñ‡∏±‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ‡∏Ñ‡∏° ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏≠‡∏≤‡∏à‡∏ó‡∏¥‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡πá‡∏ß‡πÑ‡∏õ
- **Deep Learning**: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏î‡∏≤‡∏ï‡πâ‡∏≤‡∏°‡∏≤‡∏Å, ‡∏ù‡∏∂‡∏Å‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤, ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤

### ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
- ‡πÅ‡∏ö‡πà‡∏á Train/Test (80/20)  
- ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô **MAE / RMSE / R¬≤** ‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö **Baseline = ‡πÄ‡∏î‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢**  
- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (‡∏õ‡∏µ‡∏â‡∏≤‡∏¢, ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®/‡∏†‡∏≤‡∏©‡∏≤, rating, runtime, ‡∏™‡∏ï‡∏π‡∏î‡∏¥‡πÇ‡∏≠, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‡∏Ø‡∏•‡∏Ø) ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á cross-validation/time-split

### ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á
- ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏∑‡∏≠ **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå** ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•  
- ‡∏î‡∏π‡∏Ñ‡πà‡∏≤ `appearances` (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å) ‡∏£‡πà‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏°‡∏≠  
""")

    st.subheader("üìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ)")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**Audience model (pop_score_num)**")
        st.write(rep_pop)
    with col2:
        st.markdown("**Critics model (tom_score_num)**")
        st.write(rep_tom)

    st.info("Tip: ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô ‡∏•‡∏≠‡∏á ElasticNet/LightGBM ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡πÄ‡∏ß‡∏•‡∏≤/‡πÄ‡∏£‡∏ï‡∏ï‡∏¥‡πâ‡∏á/‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö R¬≤ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô")
